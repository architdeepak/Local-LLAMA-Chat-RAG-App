# LLAMA2-ChatUI-CPU

These are the following instructions for running a local application to communicate with Llama 2 or other LLMs using CPU.

# Step 1: 
Open terminal and install nicegui.

<img width="344" alt="image" src="https://github.com/user-attachments/assets/618d7388-5071-4803-beea-555dff12283e">

Then install llama-cpp.

<img width="390" alt="image" src="https://github.com/user-attachments/assets/7761ccf0-73ef-4978-afb8-a7108f9c2e1e">


# Step 2: 
Navigate to [hugging face]([url](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/tree/main)) to download the [llama-2â€“7b-chat.Q2_K.gguf]([url](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/tree/main)) file: 
[https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/tree/main](url). Other model versions work also, as long as they are llama-cpp supported.

# Step 3: 
Clone this github repo into a folder. Move the downloaded Llama 2 model to the same folder.

# Step 4: 
Go to file explorer and open the designated fodler. Open the mainpy.py file.

<img width="581" alt="image" src="https://github.com/user-attachments/assets/aa56f778-36e6-42b2-9415-6120105aa6d6">

# Step 5: 
Ensure that the model_path parameter is set to correct path to the model file (just the file name if all steps have been followed properly)

<img width="482" alt="image" src="https://github.com/user-attachments/assets/76701e8d-f242-4b3b-8759-628f1f1ccb1e">

# Step 6: 
Open terminal and navigate to the designated folder. Then run python mainpy.py.

<img width="469" alt="image" src="https://github.com/user-attachments/assets/146e97aa-ef88-4871-901a-61d1911192b2">

# Step 7: 
A website should pop-up on your browser. Instead of being web-based, it can be used as an app.

<img width="959" alt="image" src="https://github.com/user-attachments/assets/dbf27c28-da73-45ad-93cb-1f2debbbb751">

<img width="365" alt="image" src="https://github.com/user-attachments/assets/bada262e-d95d-43fb-a8ca-81aa925c14f8">

<img width="737" alt="image" src="https://github.com/user-attachments/assets/842b5b71-8286-44f2-b1b5-3f9f1d86be13">


# Step 8: 
Now enjoy chatting with Llama 2 or another LLM!

